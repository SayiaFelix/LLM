{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b0e11f2-9ea4-48c2-b8d2-d0a4ba967827",
   "metadata": {},
   "source": [
    "# Gradio Day!\n",
    "\n",
    "Today we will build User Interfaces using the outrageously simple Gradio framework.\n",
    "\n",
    "Prepare for joy!\n",
    "\n",
    "Please note: your Gradio screens may appear in 'dark mode' or 'light mode' depending on your computer settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c44c5494-950d-4d2f-8d4f-b87b57c5b330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import google.generativeai\n",
    "import anthropic\n",
    "import ollama\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1715421-cead-400b-99af-986388a97aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr # oh yeah!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "337d5dfc-0181-4e3b-8ab9-e78e0c3f657b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key not set\n",
      "Google API Key not set\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22586021-1795-4929-8079-63f5bb4edd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Connect to OpenAI, Anthropic and Google; comment out the Claude or Google lines if you're not using them\n",
    "\n",
    "\n",
    "\n",
    "# claude = anthropic.Anthropic()\n",
    "\n",
    "# google.generativeai.configure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e6e3aaa-aa03-4beb-b6e9-c9eb06b3d741",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()\n",
    "MODEL_GPT = \"gpt-4o-mini\"\n",
    "\n",
    "MODEL = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b16e6021-6dc4-4397-985a-6679d6c8ffd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A generic system message - no more snarky adversarial AIs!\n",
    "\n",
    "system_message = \"You are a helpful assistant\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbf90c8-e151-4ede-ba60-3a4447aa9470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ebcee5d-29e8-4de6-98cf-c39b405432bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's wrap a call to GPT-4o-mini in a simple function\n",
    "\n",
    "def message_gpt(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "      ]\n",
    "    completion = openai.chat.completions.create(\n",
    "        model=MODEL_GPT,\n",
    "        messages=messages,\n",
    "    )\n",
    "    result = completion.choices[0].message.content\n",
    "    result = display(Markdown(result)) \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9958ceae-8664-45d9-ae56-bedc88c9621d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The simplicty of gradio. This might appear in \"light mode\" - I'll show you how to make this in dark mode later.\n",
    "\n",
    "# gr.Interface(fn= message_gpt, inputs=\"textbox\", outputs=\"textbox\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eeb565a0-4136-47e8-afa0-14fa4d37ac7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Data Science is an interdisciplinary field that utilizes scientific methods, algorithms, statistical techniques, and processes to extract insights and knowledge from structured and unstructured data. It combines principles from various domains, including statistics, mathematics, computer science, and domain-specific knowledge, to analyze complex data sets and inform decision-making.\n",
       "\n",
       "Key components of Data Science include:\n",
       "\n",
       "1. **Data Collection**: Gathering data from various sources, which may include databases, web scraping, APIs, or sensor data.\n",
       "\n",
       "2. **Data Preparation**: Cleaning and preprocessing data to make it suitable for analysis. This may involve handling missing values, normalizing data, and transforming data types.\n",
       "\n",
       "3. **Exploratory Data Analysis (EDA)**: Analyzing data visually and statistically to understand patterns, trends, and relationships within the data. This stage often involves data visualization techniques.\n",
       "\n",
       "4. **Modeling**: Applying statistical models and machine learning algorithms to the data to make predictions, identify patterns, or classify information. This may include techniques such as regression analysis, decision trees, clustering, and neural networks.\n",
       "\n",
       "5. **Validation and Testing**: Evaluating the models to ensure they produce reliable results. This may involve cross-validation and assessing performance metrics.\n",
       "\n",
       "6. **Deployment and Monitoring**: Implementing the model in real-world applications, and continuously monitoring its performance to ensure it operates as intended.\n",
       "\n",
       "7. **Communication**: Presenting the findings in a clear and actionable manner, using data visualizations and narratives to convey insights to stakeholders.\n",
       "\n",
       "Data Science is applied in various industries, including finance, healthcare, marketing, and technology, to solve problems, improve processes, and drive strategic decisions. It plays a crucial role in the increasingly data-driven world, helping organizations leverage their data assets effectively."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "message_gpt(\"What is Data Science?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cd9810-d74a-4270-8e83-b0132f5fc87a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02ef9b69-ef31-427d-86d0-b8c799e1c1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's wrap a call to GPT-4o-mini in a simple function\n",
    "\n",
    "def message_ollama(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "      ]\n",
    "    completion = ollama.chat(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "    )\n",
    "    result = completion.message.content\n",
    "    result = display(Markdown(result)) \n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aef7d314-2b13-436b-b02d-8de3b72b193f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "As of my last knowledge update in October 2021, the salary for data science professionals in Kenya can vary based on factors such as experience, education level, specific skills, and the industry in which one is employed. Generally, the average salary for data scientists in Kenya tends to range from KES 1,000,000 to KES 3,000,000 per year, with entry-level positions typically starting between KES 700,000 and KES 1,200,000 annually. More experienced data scientists or those in senior positions can earn significantly more, potentially exceeding KES 4,000,000 per year.\n",
       "\n",
       "For the most up-to-date salary information, I recommend checking local job boards, salary surveys, or resources like Glassdoor and PayScale for current figures specific to Kenya."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "message_gpt(\"What is Data Science salary in Kenya?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94013d1-4f27-4329-97e8-8c58db93636a",
   "metadata": {},
   "source": [
    "## User Interface time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc664b7a-c01d-4fea-a1de-ae22cdd5141a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here's a simple function\n",
    "\n",
    "def shout(text):\n",
    "    print(f\"Shout has been called with input {text}\")\n",
    "    return text.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "083ea451-d3a0-4d13-b599-93ed49b975e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shout has been called with input hello Jaey\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'HELLO JAEY'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shout(\"hello Jaey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08f1f15a-122e-4502-b112-6ee2817dda32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The simplicty of gradio. This might appear in \"light mode\" - I'll show you how to make this in dark mode later.\n",
    "\n",
    "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5cf1e89-32b8-42d6-a8a6-5e89732aa6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shout has been called with input hello\n"
     ]
    }
   ],
   "source": [
    "iface = gr.Interface(\n",
    "    fn=shout,\n",
    "    inputs=\"textbox\",\n",
    "    outputs=\"textbox\",\n",
    "    title=\"Open-Source GPT Chatbot\",\n",
    "    description=\"Chat with an open-source GPT model.\"\n",
    ")\n",
    "\n",
    "iface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9a359a4-685c-4c99-891c-bb4d1cb7f426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding share=True means that it can be accessed publically\n",
    "# A more permanent hosting is available using a platform called Spaces from HuggingFace, which we will touch on next week\n",
    "# NOTE: Some Anti-virus software and Corporate Firewalls might not like you using share=True. If you're at work on on a work network, I suggest skip this test.\n",
    "\n",
    "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\").launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd87533a-ff3a-4188-8998-5bedd5ba2da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7869\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7869/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding inbrowser=True opens up a new browser window automatically\n",
    "\n",
    "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\").launch(inbrowser=True, share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42ec007-0314-48bf-84a4-a65943649215",
   "metadata": {},
   "source": [
    "## Forcing dark mode\n",
    "\n",
    "Gradio appears in light mode or dark mode depending on the settings of the browser and computer. There is a way to force gradio to appear in dark mode, but Gradio recommends against this as it should be a user preference (particularly for accessibility reasons). But if you wish to force dark mode for your screens, below is how to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8129afa-532b-4b15-b93c-aa9cca23a546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shout has been called with input dss\n"
     ]
    }
   ],
   "source": [
    "# Define this variable and then pass js=force_dark_mode when creating the Interface\n",
    "\n",
    "force_dark_mode = \"\"\"\n",
    "function refresh() {\n",
    "    const url = new URL(window.location);\n",
    "    if (url.searchParams.get('__theme') !== 'dark') {\n",
    "        url.searchParams.set('__theme', 'dark');\n",
    "        window.location.href = url.href;\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\", js=force_dark_mode).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3cc67b26-dd5f-406d-88f6-2306ee2950c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7870\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7870/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inputs and Outputs\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=shout,\n",
    "    inputs=[gr.Textbox(label=\"Your message:\", lines=6)],\n",
    "    outputs=[gr.Textbox(label=\"Response:\", lines=8)],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f235288e-63a2-4341-935b-1441f9be969b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/markdown": [
       "As of my last update, data science salaries in Kenya can vary widely based on factors such as experience, education, industry, and location. Generally, here are some rough estimates:\n",
       "\n",
       "1. **Entry-Level Data Scientist**: KES 700,000 - KES 1,200,000 per year.\n",
       "2. **Mid-Level Data Scientist**: KES 1,200,000 - KES 2,500,000 per year.\n",
       "3. **Senior Data Scientist**: KES 2,500,000 - KES 5,000,000+ per year.\n",
       "\n",
       "In larger cities like Nairobi, salaries tend to be higher due to the concentration of tech companies and demand for data professionals. Additionally, professionals with specialized skills in machine learning, artificial intelligence, and big data technologies may command higher salaries.\n",
       "\n",
       "Keep in mind that these figures could change due to market demand and economic conditions, so it would be a good idea to consult up-to-date job listings or salary surveys for the most accurate information."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# And now - changing the function from \"shout\" to \"message_gpt\"\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=message_gpt,\n",
    "    inputs=[gr.Textbox(label=\"Your message:\", lines=6)],\n",
    "    outputs=[gr.Textbox(label=\"Response:\", lines=10)],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af9a3262-e626-4e4b-80b0-aca152405e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/markdown": [
       "Hello! How can I assist you today?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's use Markdown\n",
    "# Are you wondering why it makes any difference to set system_message when it's not referred to in the code below it?\n",
    "# I'm taking advantage of system_message being a global variable, used back in the message_gpt function (go take a look)\n",
    "# Not a great software engineering practice, but quite sommon during Jupyter Lab R&D!\n",
    "\n",
    "system_message = \"You are a helpful assistant that responds in markdown\"\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=message_gpt,\n",
    "    inputs=[gr.Textbox(label=\"Your message:\")],\n",
    "    outputs=[gr.Markdown(label=\"Response:\")],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24cc5ef-836c-4a67-90d1-75aa66e9b04d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc8e930-ba2a-4194-8f7c-044659150626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_claude(prompt):\n",
    "    result = claude.messages.stream(\n",
    "        model=\"claude-3-haiku-20240307\",\n",
    "        max_tokens=1000,\n",
    "        temperature=0.7,\n",
    "        system=system_message,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "    )\n",
    "    response = \"\"\n",
    "    with result as stream:\n",
    "        for text in stream.text_stream:\n",
    "            response += text or \"\"\n",
    "            yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0066ffd-196e-4eaf-ad1e-d492958b62af",
   "metadata": {},
   "outputs": [],
   "source": [
    "view = gr.Interface(\n",
    "    fn=stream_claude,\n",
    "    inputs=[gr.Textbox(label=\"Your message:\")],\n",
    "    outputs=[gr.Markdown(label=\"Response:\")],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5a70b9-2afe-4a7c-9bed-2429229e021b",
   "metadata": {},
   "source": [
    "## Minor improvement\n",
    "\n",
    "I've made a small improvement to this code.\n",
    "\n",
    "Previously, it had these lines:\n",
    "\n",
    "```\n",
    "for chunk in result:\n",
    "  yield chunk\n",
    "```\n",
    "\n",
    "There's actually a more elegant way to achieve this (which Python people might call more 'Pythonic'):\n",
    "\n",
    "`yield from result`\n",
    "\n",
    "I cover this in more detail in the Intermediate Python notebook in the week1 folder - take a look if you'd like more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "499122a3-4028-49ac-b228-808f1abee9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's create a call that streams back results\n",
    "# # If you'd like a refresher on Generators (the \"yield\" keyword),\n",
    "# # Please take a look at the Intermediate Python notebook in week1 folder.\n",
    "\n",
    "def stream_gpt(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "      ]\n",
    "    stream = openai.chat.completions.create(\n",
    "        model= MODEL_GPT,\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "    result = \"\"\n",
    "    for chunk in stream:\n",
    "        result += chunk.choices[0].delta.content or \"\"\n",
    "        yield result\n",
    "\n",
    "\n",
    "# def stream_gpt(prompt):\n",
    "#     messages = [\n",
    "#         {\"role\": \"system\", \"content\": system_message},\n",
    "#         {\"role\": \"user\", \"content\": prompt}\n",
    "#     ]\n",
    "#     stream = openai.chat.completions.create(\n",
    "#         model=MODEL_GPT,\n",
    "#         messages=messages,\n",
    "#         stream=True\n",
    "#     )\n",
    "#     result = \"\"\n",
    "#     for chunk in stream:\n",
    "#         result += chunk.choices[0].delta.content or \"\"\n",
    "    \n",
    "#     # Return the entire accumulated result\n",
    "#     return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "912c6cd4-3e83-470e-b073-af205e483e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7877\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7877/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view = gr.Interface(\n",
    "    fn=stream_gpt,\n",
    "    inputs=[gr.Textbox(label=\"Your message:\")],\n",
    "    outputs=[gr.Markdown(label=\"Response:\")],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb78fed8-08d2-4ea2-9108-78c3bf2272e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77f906af-f48f-40e5-8c06-c73f14d12b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def message_ollama(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    completion = ollama.chat(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "    )\n",
    "    result = completion.message.content\n",
    "    return result  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7ed719c1-5dd2-40d1-b4af-676292e188fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's wrap a call to GPT-4o-mini in a simple function\n",
    "\n",
    "def message_gpt(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "      ]\n",
    "    completion = openai.chat.completions.create(\n",
    "        model=MODEL_GPT,\n",
    "        messages=messages,\n",
    "    )\n",
    "    result = completion.choices[0].message.content\n",
    "    result = display(Markdown(result)) \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0087623a-4e31-470b-b2e6-d8d16fc7bcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_model(prompt, model):\n",
    "    if model == \"LLAMA\":\n",
    "        result = message_ollama(prompt)\n",
    "    elif model == \"GPT\":\n",
    "        result = stream_gpt(prompt)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model\")\n",
    "    \n",
    "    # Now we directly yield the result if it's not None\n",
    "    if result:\n",
    "        yield result\n",
    "    else:\n",
    "        yield \"No result returned.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8d8ce810-997c-4b6a-bc4f-1fc847ac8855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7875\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7875/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "view = gr.Interface(\n",
    "    fn=stream_model,\n",
    "    inputs=[gr.Textbox(label=\"Your message:\"), gr.Dropdown([\"LLAMA\", \"GPT\"], label=\"Select model\", value=\"LLAMA\")],\n",
    "    outputs=[gr.Markdown(label=\"Response:\")],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "\n",
    "view.launch(inbrowser=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d933865b-654c-4b92-aa45-cf389f1eda3d",
   "metadata": {},
   "source": [
    "# Building a company brochure generator\n",
    "\n",
    "Now you know how - it's simple!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d7c49b-2e0e-45b3-92ce-93ca9f962ef4",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#900;\">Before you read the next few cells</h2>\n",
    "            <span style=\"color:#900;\">\n",
    "                Try to do this yourself - go back to the company brochure in week1, day5 and add a Gradio UI to the end. Then come and look at the solution.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1626eb2e-eee8-4183-bda5-1591b58ae3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "\n",
    "class Website:\n",
    "    url: str\n",
    "    title: str\n",
    "    text: str\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(url)\n",
    "        self.body = response.content\n",
    "        soup = BeautifulSoup(self.body, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c701ec17-ecd5-4000-9f68-34634c8ed49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With massive thanks to Bill G. who noticed that a prior version of this had a bug! Now fixed.\n",
    "\n",
    "system_message = \"You are an assistant that analyzes the contents of a company website landing page \\\n",
    "and creates a short brochure about the company for prospective customers, investors and recruits. Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5def90e0-4343-4f58-9d4a-0e36e445efa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_brochure(company_name, url, model):\n",
    "    prompt = f\"Please generate a company brochure for {company_name}. Here is their landing page:\\n\"\n",
    "    try:\n",
    "        prompt += ''.join(Website(url).get_contents())  # Convert generator to string if necessary\n",
    "    except Exception as e:\n",
    "        return f\"Error processing website contents: {e}\"\n",
    "    \n",
    "    if model == \"LLAMA\":\n",
    "        result = message_ollama(prompt)\n",
    "    elif model == \"GPT\":\n",
    "        result = message_gpt(prompt)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model\")\n",
    "    \n",
    "    if result:\n",
    "        if isinstance(result, str):\n",
    "            yield result\n",
    "        else:\n",
    "            yield ''.join(result)  # Handle non-string result\n",
    "    else:\n",
    "        yield \"No result returned from the model.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "66399365-5d67-4984-9d47-93ed26c0bd3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7880\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7880/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/markdown": [
       "# Eclectics International Brochure\n",
       "\n",
       "---\n",
       "\n",
       "## **Welcome to Eclectics International**\n",
       "\n",
       "**Simplifying Lives Digitally**\n",
       "\n",
       "At Eclectics, we are a pioneering technology company dedicated to transforming industries worldwide through innovative, customized software solutions specifically designed for banking, finance, agriculture, transport, and the public sector.\n",
       "\n",
       "**Our Vision:**\n",
       "To enable sustainable economic growth by fostering a resilient SME sector, ensuring that advanced technology is accessible and affordable.\n",
       "\n",
       "---\n",
       "\n",
       "## **Why Choose Eclectics?**\n",
       "\n",
       "- **Experience:** Over 13 years in the industry.\n",
       "- **Global Reach:** Serving clients in over 30 countries with 290+ satisfied clients and 1500+ completed projects.\n",
       "- **Trusted Solutions:** Our reputation is built on providing state-of-the-art tailored solutions that meet the unique needs of our clients.\n",
       "\n",
       "---\n",
       "\n",
       "## **Our Key Solutions**\n",
       "\n",
       "- **eConnect ESB Gateway:** Seamless data integration between multiple systems.\n",
       "- **Agency Banking:** Promoting financial inclusivity for unbanked populations.\n",
       "- **Internet & Mobile Banking:** Accessible banking services available anywhere, anytime.\n",
       "- **SME Automation:** Tailored solutions that enable efficient operations in small and medium enterprises.\n",
       "- **Payment Aggregation Services:** Authorized services to facilitate transactions across platforms.\n",
       "\n",
       "---\n",
       "\n",
       "## **Industries We Serve**\n",
       "\n",
       "- **Banking & Finance**\n",
       "- **Agritech**\n",
       "- **Transport**\n",
       "- **Public Sector**\n",
       "- **Insurance**\n",
       "- **SACCOs (Savings and Credit Cooperative Organizations)**\n",
       "\n",
       "---\n",
       "\n",
       "## **Our Clients**\n",
       "\n",
       "Eclectics boasts partnerships with various recognized industry leaders, including:\n",
       "\n",
       "- **KCB Bank**\n",
       "- **Faulu Bank**\n",
       "- **Jubilee Insurance**\n",
       "- **Central Bank of Kenya**\n",
       "- **Fortune SACCO**\n",
       "- **UN SACCO**\n",
       "\n",
       "---\n",
       "\n",
       "## **Technological Partnership**\n",
       "\n",
       "We collaborate with renowned technology providers like **Microsoft**, offering products such as:\n",
       "\n",
       "- **Microsoft Azure**\n",
       "- **Power BI**\n",
       "- **Microsoft Dynamics ERP & CRM**\n",
       "\n",
       "Our licensing solutions for software from Microsoft, RedHat, and Oracle ensure that your organization remains compliant and efficient.\n",
       "\n",
       "---\n",
       "\n",
       "## **Customer Commitment**\n",
       "\n",
       "At Eclectics, we prioritize providing an excellent customer experience through:\n",
       "\n",
       "- **24-Hour Customer Support:** For assistance at any time.\n",
       "- **Enhanced Analytics:** Data-driven insights for better decision-making.\n",
       "- **Fraud Mitigation:** Advanced security systems to protect your transactions.\n",
       "\n",
       "---\n",
       "\n",
       "## **Let's Connect!**\n",
       "\n",
       "For inquiries and more information, reach us at:\n",
       "\n",
       "**Phone:** +254 709 646 000  \n",
       "**Email:** [talktous@eclectics.io](mailto:talktous@eclectics.io)\n",
       "\n",
       "**Location:**  \n",
       "3rd Floor Utumishi Co-op House  \n",
       "Mamlaka Road, Nairobi, Kenya\n",
       "\n",
       "---\n",
       "\n",
       "**Follow us on our social media for updates and insights!**\n",
       "\n",
       "### **Empowering Businesses, Transforming Lives.**\n",
       "\n",
       "--- \n",
       "\n",
       "*All content is Â© 2024 Eclectics International. All rights reserved.*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gradio interface\n",
    "view = gr.Interface(\n",
    "    fn=stream_brochure,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Company name:\"),\n",
    "        gr.Textbox(label=\"Landing page URL including http:// or https://\"),\n",
    "        gr.Dropdown([\"LLAMA\", \"GPT\"], label=\"Select model\")\n",
    "    ],\n",
    "    outputs=[gr.Markdown(label=\"Brochure:\")],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "\n",
    "view.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede97ca3-a0f8-4f6e-be17-d1de7fef9cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
